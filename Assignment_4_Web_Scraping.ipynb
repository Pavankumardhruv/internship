{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b671c7e",
   "metadata": {},
   "source": [
    "## !pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4987746",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in ./opt/anaconda3/lib/python3.9/site-packages (4.10.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in ./opt/anaconda3/lib/python3.9/site-packages (from selenium) (0.10.3)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in ./opt/anaconda3/lib/python3.9/site-packages (from selenium) (2022.9.24)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in ./opt/anaconda3/lib/python3.9/site-packages (from selenium) (1.26.11)\n",
      "Requirement already satisfied: trio~=0.17 in ./opt/anaconda3/lib/python3.9/site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied: sniffio in ./opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: outcome in ./opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: attrs>=20.1.0 in ./opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: idna in ./opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in ./opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.1.2)\n",
      "Requirement already satisfied: sortedcontainers in ./opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in ./opt/anaconda3/lib/python3.9/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in ./opt/anaconda3/lib/python3.9/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in ./opt/anaconda3/lib/python3.9/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9ca970c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: webdriver-manager in ./opt/anaconda3/lib/python3.9/site-packages (3.8.6)\n",
      "Requirement already satisfied: tqdm in ./opt/anaconda3/lib/python3.9/site-packages (from webdriver-manager) (4.64.1)\n",
      "Requirement already satisfied: packaging in ./opt/anaconda3/lib/python3.9/site-packages (from webdriver-manager) (21.3)\n",
      "Requirement already satisfied: requests in ./opt/anaconda3/lib/python3.9/site-packages (from webdriver-manager) (2.28.1)\n",
      "Requirement already satisfied: python-dotenv in ./opt/anaconda3/lib/python3.9/site-packages (from webdriver-manager) (1.0.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in ./opt/anaconda3/lib/python3.9/site-packages (from packaging->webdriver-manager) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./opt/anaconda3/lib/python3.9/site-packages (from requests->webdriver-manager) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./opt/anaconda3/lib/python3.9/site-packages (from requests->webdriver-manager) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./opt/anaconda3/lib/python3.9/site-packages (from requests->webdriver-manager) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in ./opt/anaconda3/lib/python3.9/site-packages (from requests->webdriver-manager) (2.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85fea7d",
   "metadata": {},
   "source": [
    "Q1. Scrape the details of most viewed videos on YouTube from Wikipedia. Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7934f316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "99232cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\"\n",
    "try:\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    \n",
    "    videos = []\n",
    "    table = soup.find('table',class_=\"wikitable sortable\")\n",
    "    rows = table.find_all(\"tr\")[1:] #skip the header\n",
    "    \n",
    "    for row in rows:\n",
    "        columns = row.find_all(\"td\")\n",
    "        if len(columns)>=5:\n",
    "            rank = columns[0].get_text(strip=True)\n",
    "            name = columns[1].get_text(strip=True)\n",
    "            artist = columns[2].get_text(strip=True)\n",
    "            views = columns[3].get_text(strip=True)\n",
    "            date =columns[4].get_text(strip=True)\n",
    "            \n",
    "            videos.append((rank, name, artist, views, date))\n",
    "except requests.RequestException as e:\n",
    "    print(\"Error fetching the page:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "94c287cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranks</th>\n",
       "      <th>Names</th>\n",
       "      <th>Artists</th>\n",
       "      <th>Views</th>\n",
       "      <th>Upload Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[6]</td>\n",
       "      <td>Pinkfong Baby Shark- children's songs</td>\n",
       "      <td>13.18</td>\n",
       "      <td>June 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[9]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>8.23</td>\n",
       "      <td>January 12, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[16]</td>\n",
       "      <td>LooLoo Kids - nursery rhymes</td>\n",
       "      <td>6.76</td>\n",
       "      <td>October 8, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Bath Song\"[17]</td>\n",
       "      <td>Cocomelon- nursery rhymes</td>\n",
       "      <td>6.33</td>\n",
       "      <td>May 2, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Shape of You\"[18]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>6.05</td>\n",
       "      <td>January 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"[21]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>5.98</td>\n",
       "      <td>April 6, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Wheels on the Bus\"[26]</td>\n",
       "      <td>Cocomelon- nursery rhymes</td>\n",
       "      <td>5.46</td>\n",
       "      <td>May 24, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[27]</td>\n",
       "      <td>ChuChu TV- children's songs</td>\n",
       "      <td>5.42</td>\n",
       "      <td>March 6, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Uptown Funk\"[28]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>5.00</td>\n",
       "      <td>November 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[29]</td>\n",
       "      <td>Miroshka TV - children's songs</td>\n",
       "      <td>4.94</td>\n",
       "      <td>February 27, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"[30]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>4.86</td>\n",
       "      <td>July 15, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Masha and the Bear– Recipe for Disaster\"[35]</td>\n",
       "      <td>Get Movies - children's songs</td>\n",
       "      <td>4.55</td>\n",
       "      <td>January 31, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[36]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>4.41</td>\n",
       "      <td>April 5, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Axel F\"[37]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>4.00</td>\n",
       "      <td>June 16, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Sugar\"[38]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.91</td>\n",
       "      <td>January 14, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Roar\"[39]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.84</td>\n",
       "      <td>September 5, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Counting Stars\"[40]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>3.84</td>\n",
       "      <td>May 31, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[41]</td>\n",
       "      <td>Cocomelon- nursery rhymes</td>\n",
       "      <td>3.73</td>\n",
       "      <td>June 25, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Sorry\"[42]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>3.69</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[43]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>3.68</td>\n",
       "      <td>June 4, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Thinking Out Loud\"[44]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.63</td>\n",
       "      <td>October 7, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Lakdi Ki Kathi\"[45]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>3.63</td>\n",
       "      <td>June 14, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Dark Horse\"[46]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.56</td>\n",
       "      <td>February 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Perfect\"[47]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.51</td>\n",
       "      <td>November 9, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Faded\"[48]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>3.49</td>\n",
       "      <td>December 3, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Let Her Go\"[49]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>3.48</td>\n",
       "      <td>July 25, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[50]</td>\n",
       "      <td>Kiddiestv Hindi - children's songs</td>\n",
       "      <td>3.51</td>\n",
       "      <td>January 26, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Girls Like You\"[51]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.45</td>\n",
       "      <td>May 31, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Bailando\"[52]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>3.43</td>\n",
       "      <td>April 11, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Lean On\"[53]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>3.43</td>\n",
       "      <td>March 22, 2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ranks                                            Names  \\\n",
       "0     1.                            \"Baby Shark Dance\"[6]   \n",
       "1     2.                                   \"Despacito\"[9]   \n",
       "2     3.                       \"Johny Johny Yes Papa\"[16]   \n",
       "3     4.                                  \"Bath Song\"[17]   \n",
       "4     5.                               \"Shape of You\"[18]   \n",
       "5     6.                              \"See You Again\"[21]   \n",
       "6     7.                          \"Wheels on the Bus\"[26]   \n",
       "7     8.                \"Phonics Song with Two Words\"[27]   \n",
       "8     9.                                \"Uptown Funk\"[28]   \n",
       "9    10.  \"Learning Colors – Colorful Eggs on a Farm\"[29]   \n",
       "10   11.                              \"Gangnam Style\"[30]   \n",
       "11   12.    \"Masha and the Bear– Recipe for Disaster\"[35]   \n",
       "12   13.                             \"Dame Tu Cosita\"[36]   \n",
       "13   14.                                     \"Axel F\"[37]   \n",
       "14   15.                                      \"Sugar\"[38]   \n",
       "15   16.                                       \"Roar\"[39]   \n",
       "16   17.                             \"Counting Stars\"[40]   \n",
       "17   18.                        \"Baa Baa Black Sheep\"[41]   \n",
       "18   19.                                      \"Sorry\"[42]   \n",
       "19   20.           \"Waka Waka (This Time for Africa)\"[43]   \n",
       "20   21.                          \"Thinking Out Loud\"[44]   \n",
       "21   22.                             \"Lakdi Ki Kathi\"[45]   \n",
       "22   23.                                 \"Dark Horse\"[46]   \n",
       "23   24.                                    \"Perfect\"[47]   \n",
       "24   25.                                      \"Faded\"[48]   \n",
       "25   26.                                 \"Let Her Go\"[49]   \n",
       "26   27.          \"Humpty the train on a fruits ride\"[50]   \n",
       "27   28.                             \"Girls Like You\"[51]   \n",
       "28   29.                                   \"Bailando\"[52]   \n",
       "29   30.                                    \"Lean On\"[53]   \n",
       "\n",
       "                                  Artists  Views        Upload Date  \n",
       "0   Pinkfong Baby Shark- children's songs  13.18      June 17, 2016  \n",
       "1                              Luis Fonsi   8.23   January 12, 2017  \n",
       "2            LooLoo Kids - nursery rhymes   6.76    October 8, 2016  \n",
       "3               Cocomelon- nursery rhymes   6.33        May 2, 2018  \n",
       "4                              Ed Sheeran   6.05   January 30, 2017  \n",
       "5                             Wiz Khalifa   5.98      April 6, 2015  \n",
       "6               Cocomelon- nursery rhymes   5.46       May 24, 2018  \n",
       "7             ChuChu TV- children's songs   5.42      March 6, 2014  \n",
       "8                             Mark Ronson   5.00  November 19, 2014  \n",
       "9          Miroshka TV - children's songs   4.94  February 27, 2018  \n",
       "10                                    Psy   4.86      July 15, 2012  \n",
       "11          Get Movies - children's songs   4.55   January 31, 2012  \n",
       "12                              El Chombo   4.41      April 5, 2018  \n",
       "13                             Crazy Frog   4.00      June 16, 2009  \n",
       "14                               Maroon 5   3.91   January 14, 2015  \n",
       "15                             Katy Perry   3.84  September 5, 2013  \n",
       "16                            OneRepublic   3.84       May 31, 2013  \n",
       "17              Cocomelon- nursery rhymes   3.73      June 25, 2018  \n",
       "18                          Justin Bieber   3.69   October 22, 2015  \n",
       "19                                Shakira   3.68       June 4, 2010  \n",
       "20                             Ed Sheeran   3.63    October 7, 2014  \n",
       "21                           Jingle Toons   3.63      June 14, 2018  \n",
       "22                             Katy Perry   3.56  February 20, 2014  \n",
       "23                             Ed Sheeran   3.51   November 9, 2017  \n",
       "24                            Alan Walker   3.49   December 3, 2015  \n",
       "25                              Passenger   3.48      July 25, 2012  \n",
       "26     Kiddiestv Hindi - children's songs   3.51   January 26, 2018  \n",
       "27                               Maroon 5   3.45       May 31, 2018  \n",
       "28                       Enrique Iglesias   3.43     April 11, 2014  \n",
       "29                            Major Lazer   3.43     March 22, 2015  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a DataFrame from the scrapped data\n",
    "columns = ['Ranks','Names','Artists','Views','Upload Date']\n",
    "df =pd.DataFrame(videos, columns=columns)\n",
    "\n",
    "#Print the DataFrame\n",
    "df\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b243815",
   "metadata": {},
   "source": [
    "Q2. Scrape the details team India’s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1 ODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "91f6e88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium                                  #library that is used to work with selenium\n",
    "from selenium import webdriver                   #importing webdriver module from selenium to open automated chrome window\n",
    "import pandas as pd                              #to create DataFrame\n",
    "from selenium.webdriver.common.by import By      #importing inbuilt class By \n",
    "import warnings                                  #to ignore any sort of warning\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time                                      #use to stop search engine for few seconds\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8f425f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\" https://www.bcci.tv/\")  #search for bcci.tv in automated Chrome browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6c7dd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    element = driver.find_element(By.XPATH,'//li[@class=\"nav-item\"]')\n",
    "    element.click()\n",
    "except NoSuchElementException as e:\n",
    "    print('error occured', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7167b4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    button = wait.until(EC.presence_of_element_located((By.XPATH,'/html/body/div[2]/div[2]/div/div/div/div[2]/div[3]/div[2]/div/button')))\n",
    "    button.click()\n",
    "except NoSuchElementException as e:\n",
    "    Print('Error occured', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f019181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout: Button not found. No more content to load.\n",
      "Finished clicking buttons.\n"
     ]
    }
   ],
   "source": [
    "timeout = 10  # Timeout in seconds\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        wait = WebDriverWait(driver, timeout)\n",
    "        button = wait.until(EC.presence_of_element_located((By.XPATH,'/html/body/div[2]/div[2]/div/div/div/div[2]/div[3]/div[2]/div/button')))\n",
    "        button.click()\n",
    "    except NoSuchElementException:\n",
    "        print('Button not found. No more content to load.')\n",
    "        break  # Exit the loop if button is not found\n",
    "    except TimeoutException:\n",
    "        print('Timeout: Button not found. No more content to load.')\n",
    "        break  # Exit the loop if button is not found within the timeout\n",
    "\n",
    "print('Finished clicking buttons.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5cdf5f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_title = []\n",
    "match = driver.find_elements(By.XPATH,'//h5[@class=\"match-tournament-name ng-binding\"]')\n",
    "for i in match:\n",
    "    m=i.text\n",
    "    match_title.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d5ba6992",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = []\n",
    "series_ = driver.find_elements(By.XPATH,'//span[@class=\"matchOrderText ng-binding ng-scope\"]')\n",
    "for i in series_:\n",
    "    s=i.text\n",
    "    series.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c3a31569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c5d20e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "place=[]\n",
    "place_ = driver.find_elements(By.XPATH,'//div[@class=\"match-place ng-scope\"]')\n",
    "for i in place_:\n",
    "    p=i.text.split('-')[1].strip()\n",
    "    place.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ac5f7755",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = []\n",
    "date = driver.find_elements(By.XPATH,'//div[@class=\"match-dates ng-binding\"]')\n",
    "for i in date:\n",
    "    dates.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "44916bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "timings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "31c34f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = driver.find_elements(By.XPATH,'//div[@class=\"match-time no-margin ng-binding\"]')\n",
    "for i in time:\n",
    "    timings.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fc3132cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38, 38, 38, 38, 38)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(match_title),len(series),len(place),len(dates),len(timings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "20d2dc2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Matches</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Dates</th>\n",
       "      <th>Timings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INDIA TOUR OF IRELAND 2023</td>\n",
       "      <td>1st T20I -</td>\n",
       "      <td>The Village, Dublin</td>\n",
       "      <td>18 AUG 2023</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INDIA TOUR OF IRELAND 2023</td>\n",
       "      <td>2nd T20I -</td>\n",
       "      <td>The Village, Dublin</td>\n",
       "      <td>20 AUG 2023</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDIA TOUR OF IRELAND 2023</td>\n",
       "      <td>3rd T20I -</td>\n",
       "      <td>The Village, Dublin</td>\n",
       "      <td>23 AUG 2023</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASIA CUP 2023</td>\n",
       "      <td>1st ODI -</td>\n",
       "      <td>Pallekele International Cricket Stadium, Palle...</td>\n",
       "      <td>2 SEP 2023</td>\n",
       "      <td>10:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASIA CUP 2023</td>\n",
       "      <td>2nd ODI -</td>\n",
       "      <td>Pallekele International Cricket Stadium, Palle...</td>\n",
       "      <td>4 SEP 2023</td>\n",
       "      <td>10:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>1st ODI -</td>\n",
       "      <td>Punjab Cricket Association IS Bindra Stadium, ...</td>\n",
       "      <td>22 SEP 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>2nd ODI -</td>\n",
       "      <td>Holkar Cricket Stadium, Indore</td>\n",
       "      <td>24 SEP 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>3rd ODI -</td>\n",
       "      <td>Saurashtra Cricket Association Stadium, Rajkot</td>\n",
       "      <td>27 SEP 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>1st ODI -</td>\n",
       "      <td>MA Chidambaram Stadium, Chennai</td>\n",
       "      <td>8 OCT 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>2nd ODI -</td>\n",
       "      <td>Arun Jaitley Stadium, Delhi</td>\n",
       "      <td>11 OCT 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>3rd ODI -</td>\n",
       "      <td>Narendra Modi Stadium, Ahmedabad</td>\n",
       "      <td>14 OCT 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>4th ODI -</td>\n",
       "      <td>Maharashtra Cricket Association Stadium, Pune</td>\n",
       "      <td>19 OCT 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>5th ODI -</td>\n",
       "      <td>Himachal Pradesh Cricket Association Stadium, ...</td>\n",
       "      <td>22 OCT 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>6th ODI -</td>\n",
       "      <td>Bharat Ratna Shri Atal Bihari Vajpayee Ekana C...</td>\n",
       "      <td>29 OCT 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>7th ODI -</td>\n",
       "      <td>Wankhede Stadium, Mumbai</td>\n",
       "      <td>2 NOV 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>8th ODI -</td>\n",
       "      <td>Eden Gardens, Kolkata</td>\n",
       "      <td>5 NOV 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>9th ODI -</td>\n",
       "      <td>M Chinnaswamy Stadium, Bengaluru</td>\n",
       "      <td>12 NOV 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>1st T20I -</td>\n",
       "      <td>Dr YS Rajasekhara Reddy ACA</td>\n",
       "      <td>23 NOV 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>2nd T20I -</td>\n",
       "      <td>Greenfield International Stadium, Thiruvananth...</td>\n",
       "      <td>26 NOV 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>3rd T20I -</td>\n",
       "      <td>Barsapara Cricket Stadium, Guwahati</td>\n",
       "      <td>28 NOV 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>4th T20I -</td>\n",
       "      <td>Vidarbha Cricket Association Stadium, Nagpur</td>\n",
       "      <td>1 DEC 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>5th T20I -</td>\n",
       "      <td>Rajiv Gandhi International Stadium, Hyderabad</td>\n",
       "      <td>3 DEC 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>1st T20I -</td>\n",
       "      <td>Kingsmead, Durban</td>\n",
       "      <td>10 DEC 2023</td>\n",
       "      <td>9:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>2nd T20I -</td>\n",
       "      <td>St George's Park, Gqeberha</td>\n",
       "      <td>12 DEC 2023</td>\n",
       "      <td>9:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>3rd T20I -</td>\n",
       "      <td>The Wanderers Stadium, Johannesburg</td>\n",
       "      <td>14 DEC 2023</td>\n",
       "      <td>9:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>1st ODI -</td>\n",
       "      <td>Johannesburg</td>\n",
       "      <td>17 DEC 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>2nd ODI -</td>\n",
       "      <td>St George's Park, Gqeberha</td>\n",
       "      <td>19 DEC 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>3rd ODI -</td>\n",
       "      <td>Boland Park, Paarl</td>\n",
       "      <td>21 DEC 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>1st Test -</td>\n",
       "      <td>SuperSport Park, Centurion</td>\n",
       "      <td>26 DEC 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>2nd Test -</td>\n",
       "      <td>Newlands, Cape Town</td>\n",
       "      <td>3 JAN 2024</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>AFGHANISTAN TOUR OF INDIA 2023-24</td>\n",
       "      <td>1st T20I -</td>\n",
       "      <td>Punjab Cricket Association IS Bindra Stadium, ...</td>\n",
       "      <td>11 JAN 2024</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>AFGHANISTAN TOUR OF INDIA 2023-24</td>\n",
       "      <td>2nd T20I -</td>\n",
       "      <td>Holkar Cricket Stadium, Indore</td>\n",
       "      <td>14 JAN 2024</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>AFGHANISTAN TOUR OF INDIA 2023-24</td>\n",
       "      <td>3rd T20I -</td>\n",
       "      <td>M Chinnaswamy Stadium, Bengaluru</td>\n",
       "      <td>17 JAN 2024</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>1st Test -</td>\n",
       "      <td>Rajiv Gandhi International Stadium, Hyderabad</td>\n",
       "      <td>25 JAN 2024</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>2nd Test -</td>\n",
       "      <td>Dr YS Rajasekhara Reddy ACA</td>\n",
       "      <td>2 FEB 2024</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>3rd Test -</td>\n",
       "      <td>Saurashtra Cricket Association Stadium, Rajkot</td>\n",
       "      <td>15 FEB 2024</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>4th Test -</td>\n",
       "      <td>JSCA International Stadium Complex, Ranchi</td>\n",
       "      <td>23 FEB 2024</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>5th Test -</td>\n",
       "      <td>Himachal Pradesh Cricket Association Stadium, ...</td>\n",
       "      <td>7 MAR 2024</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Matches      Series  \\\n",
       "0           INDIA TOUR OF IRELAND 2023  1st T20I -   \n",
       "1           INDIA TOUR OF IRELAND 2023  2nd T20I -   \n",
       "2           INDIA TOUR OF IRELAND 2023  3rd T20I -   \n",
       "3                        ASIA CUP 2023   1st ODI -   \n",
       "4                        ASIA CUP 2023   2nd ODI -   \n",
       "5      AUSTRALIA TOUR OF INDIA 2023-24   1st ODI -   \n",
       "6      AUSTRALIA TOUR OF INDIA 2023-24   2nd ODI -   \n",
       "7      AUSTRALIA TOUR OF INDIA 2023-24   3rd ODI -   \n",
       "8              ICC MENS WORLD CUP 2023   1st ODI -   \n",
       "9              ICC MENS WORLD CUP 2023   2nd ODI -   \n",
       "10             ICC MENS WORLD CUP 2023   3rd ODI -   \n",
       "11             ICC MENS WORLD CUP 2023   4th ODI -   \n",
       "12             ICC MENS WORLD CUP 2023   5th ODI -   \n",
       "13             ICC MENS WORLD CUP 2023   6th ODI -   \n",
       "14             ICC MENS WORLD CUP 2023   7th ODI -   \n",
       "15             ICC MENS WORLD CUP 2023   8th ODI -   \n",
       "16             ICC MENS WORLD CUP 2023   9th ODI -   \n",
       "17     AUSTRALIA TOUR OF INDIA 2023-24  1st T20I -   \n",
       "18     AUSTRALIA TOUR OF INDIA 2023-24  2nd T20I -   \n",
       "19     AUSTRALIA TOUR OF INDIA 2023-24  3rd T20I -   \n",
       "20     AUSTRALIA TOUR OF INDIA 2023-24  4th T20I -   \n",
       "21     AUSTRALIA TOUR OF INDIA 2023-24  5th T20I -   \n",
       "22  INDIA TOUR OF SOUTH AFRICA 2023-24  1st T20I -   \n",
       "23  INDIA TOUR OF SOUTH AFRICA 2023-24  2nd T20I -   \n",
       "24  INDIA TOUR OF SOUTH AFRICA 2023-24  3rd T20I -   \n",
       "25  INDIA TOUR OF SOUTH AFRICA 2023-24   1st ODI -   \n",
       "26  INDIA TOUR OF SOUTH AFRICA 2023-24   2nd ODI -   \n",
       "27  INDIA TOUR OF SOUTH AFRICA 2023-24   3rd ODI -   \n",
       "28  INDIA TOUR OF SOUTH AFRICA 2023-24  1st Test -   \n",
       "29  INDIA TOUR OF SOUTH AFRICA 2023-24  2nd Test -   \n",
       "30   AFGHANISTAN TOUR OF INDIA 2023-24  1st T20I -   \n",
       "31   AFGHANISTAN TOUR OF INDIA 2023-24  2nd T20I -   \n",
       "32   AFGHANISTAN TOUR OF INDIA 2023-24  3rd T20I -   \n",
       "33       ENGLAND TOUR OF INDIA 2023-24  1st Test -   \n",
       "34       ENGLAND TOUR OF INDIA 2023-24  2nd Test -   \n",
       "35       ENGLAND TOUR OF INDIA 2023-24  3rd Test -   \n",
       "36       ENGLAND TOUR OF INDIA 2023-24  4th Test -   \n",
       "37       ENGLAND TOUR OF INDIA 2023-24  5th Test -   \n",
       "\n",
       "                                                Place        Dates  \\\n",
       "0                                 The Village, Dublin  18 AUG 2023   \n",
       "1                                 The Village, Dublin  20 AUG 2023   \n",
       "2                                 The Village, Dublin  23 AUG 2023   \n",
       "3   Pallekele International Cricket Stadium, Palle...   2 SEP 2023   \n",
       "4   Pallekele International Cricket Stadium, Palle...   4 SEP 2023   \n",
       "5   Punjab Cricket Association IS Bindra Stadium, ...  22 SEP 2023   \n",
       "6                      Holkar Cricket Stadium, Indore  24 SEP 2023   \n",
       "7      Saurashtra Cricket Association Stadium, Rajkot  27 SEP 2023   \n",
       "8                     MA Chidambaram Stadium, Chennai   8 OCT 2023   \n",
       "9                         Arun Jaitley Stadium, Delhi  11 OCT 2023   \n",
       "10                   Narendra Modi Stadium, Ahmedabad  14 OCT 2023   \n",
       "11      Maharashtra Cricket Association Stadium, Pune  19 OCT 2023   \n",
       "12  Himachal Pradesh Cricket Association Stadium, ...  22 OCT 2023   \n",
       "13  Bharat Ratna Shri Atal Bihari Vajpayee Ekana C...  29 OCT 2023   \n",
       "14                           Wankhede Stadium, Mumbai   2 NOV 2023   \n",
       "15                              Eden Gardens, Kolkata   5 NOV 2023   \n",
       "16                   M Chinnaswamy Stadium, Bengaluru  12 NOV 2023   \n",
       "17                        Dr YS Rajasekhara Reddy ACA  23 NOV 2023   \n",
       "18  Greenfield International Stadium, Thiruvananth...  26 NOV 2023   \n",
       "19                Barsapara Cricket Stadium, Guwahati  28 NOV 2023   \n",
       "20       Vidarbha Cricket Association Stadium, Nagpur   1 DEC 2023   \n",
       "21      Rajiv Gandhi International Stadium, Hyderabad   3 DEC 2023   \n",
       "22                                  Kingsmead, Durban  10 DEC 2023   \n",
       "23                         St George's Park, Gqeberha  12 DEC 2023   \n",
       "24                The Wanderers Stadium, Johannesburg  14 DEC 2023   \n",
       "25                                       Johannesburg  17 DEC 2023   \n",
       "26                         St George's Park, Gqeberha  19 DEC 2023   \n",
       "27                                 Boland Park, Paarl  21 DEC 2023   \n",
       "28                         SuperSport Park, Centurion  26 DEC 2023   \n",
       "29                                Newlands, Cape Town   3 JAN 2024   \n",
       "30  Punjab Cricket Association IS Bindra Stadium, ...  11 JAN 2024   \n",
       "31                     Holkar Cricket Stadium, Indore  14 JAN 2024   \n",
       "32                   M Chinnaswamy Stadium, Bengaluru  17 JAN 2024   \n",
       "33      Rajiv Gandhi International Stadium, Hyderabad  25 JAN 2024   \n",
       "34                        Dr YS Rajasekhara Reddy ACA   2 FEB 2024   \n",
       "35     Saurashtra Cricket Association Stadium, Rajkot  15 FEB 2024   \n",
       "36         JSCA International Stadium Complex, Ranchi  23 FEB 2024   \n",
       "37  Himachal Pradesh Cricket Association Stadium, ...   7 MAR 2024   \n",
       "\n",
       "         Timings  \n",
       "0    7:30 PM IST  \n",
       "1    7:30 PM IST  \n",
       "2    7:30 PM IST  \n",
       "3   10:00 AM IST  \n",
       "4   10:00 AM IST  \n",
       "5    1:30 PM IST  \n",
       "6    1:30 PM IST  \n",
       "7    1:30 PM IST  \n",
       "8    2:00 PM IST  \n",
       "9    2:00 PM IST  \n",
       "10   2:00 PM IST  \n",
       "11   2:00 PM IST  \n",
       "12   2:00 PM IST  \n",
       "13   2:00 PM IST  \n",
       "14   2:00 PM IST  \n",
       "15   2:00 PM IST  \n",
       "16   2:00 PM IST  \n",
       "17   7:00 PM IST  \n",
       "18   7:00 PM IST  \n",
       "19   7:00 PM IST  \n",
       "20   7:00 PM IST  \n",
       "21   7:00 PM IST  \n",
       "22   9:30 PM IST  \n",
       "23   9:30 PM IST  \n",
       "24   9:30 PM IST  \n",
       "25   2:00 PM IST  \n",
       "26   2:00 PM IST  \n",
       "27   2:00 PM IST  \n",
       "28   1:30 PM IST  \n",
       "29   1:30 PM IST  \n",
       "30   7:00 PM IST  \n",
       "31   7:00 PM IST  \n",
       "32   7:00 PM IST  \n",
       "33   9:30 AM IST  \n",
       "34   9:30 AM IST  \n",
       "35   9:30 AM IST  \n",
       "36   9:30 AM IST  \n",
       "37   9:30 AM IST  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.DataFrame({'Matches': match_title,'Series': series, 'Place': place,'Dates': dates, 'Timings': timings})\n",
    "df\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13967019",
   "metadata": {},
   "source": [
    "Q3. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details: A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "6207b169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium                                  #library that is used to work with selenium\n",
    "from selenium import webdriver                   #importing webdriver module from selenium to open automated chrome window\n",
    "import pandas as pd                              #to create DataFrame\n",
    "from selenium.webdriver.common.by import By      #importing inbuilt class By \n",
    "import warnings                                  #to ignore any sort of warning\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time                                      #use to stop search engine for few seconds\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "8fc06cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"http://statisticstimes.com/ \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "b3034fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Click on the economy button in the webpage\n",
    "button = driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/button')\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "1aba0d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting India from the dropdown\n",
    "dropdown = driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]')\n",
    "dropdown.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "08e17e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the 'GDP of Indian states'\n",
    "article = driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')\n",
    "article.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "7547fd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDP_table= [] #Creating an empty list to scrap the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "81916541",
   "metadata": {},
   "outputs": [],
   "source": [
    "wait =WebDriverWait(driver, 10)\n",
    "GDP = wait.until(EC.presence_of_element_located((By.XPATH, '/html/body/div[3]/div[2]/div[5]/div[1]/div/table')))\n",
    "data =GDP.find_elements(By.XPATH, '/html/body/div[3]/div[2]/div[5]/div[1]/div/table/tbody')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "a10a2a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data:\n",
    "    d=i.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "20b68220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 Maharashtra - 2,632,792 13.94% 399.921 - 2,039,074\\n2 Tamil Nadu 1,845,853 1,630,208 8.63% 247.629 1,312,929 1,215,307\\n3 Uttar Pradesh 1,687,818 1,584,764 8.39% 240.726 1,166,817 1,123,982\\n4 Gujarat - 1,502,899 7.96% 228.290 - 1,186,379\\n5 Karnataka 1,631,977 1,493,127 7.91% 226.806 1,156,039 1,091,077\\n6 West Bengal 1,253,832 1,089,898 5.77% 165.556 793,223 739,525\\n7 Rajasthan 1,020,989 942,586 4.99% 143.179 711,627 677,428\\n8 Andhra Pradesh 972,782 862,957 4.57% 131.083 672,018 621,301\\n9 Telangana 969,604 861,031 4.56% 130.791 663,258 612,828\\n10 Madhya Pradesh 906,672 809,592 4.29% 122.977 561,801 522,009\\n11 Kerala - 781,653 4.14% 118.733 - 559,412\\n12 Delhi 856,112 774,870 4.10% 117.703 634,408 590,569\\n13 Haryana 831,610 734,163 3.89% 111.519 572,240 531,085\\n14 Bihar 611,804 530,363 2.81% 80.562 414,977 375,651\\n15 Punjab 574,760 526,376 2.79% 79.957 418,868 397,669\\n16 Odisha 521,275 487,805 2.58% 74.098 396,499 376,877\\n17 Assam - 315,881 1.67% 47.982 - 234,048\\n18 Chhattisgarh 329,180 304,063 1.61% 46.187 243,477 231,182\\n19 Jharkhand 328,598 297,204 1.57% 45.145 240,036 224,986\\n20 Uttarakhand - 245,895 1.30% 37.351 - 193,273\\n21 Jammu & Kashmir - 155,956 0.83% 23.690 - 112,755\\n22 Himachal Pradesh 165,472 153,845 0.81% 23.369 124,403 117,851\\n23 Goa 80,449 73,170 0.39% 11.115 63,408 57,787\\n24 Tripura 55,984 49,845 0.26% 7.571 40,583 36,963\\n25 Chandigarh - 42,114 0.22% 6.397 - 31,192\\n26 Puducherry 38,253 34,433 0.18% 5.230 25,093 23,013\\n27 Meghalaya 36,572 33,481 0.18% 5.086 26,695 24,682\\n28 Sikkim 32,496 28,723 0.15% 4.363 20,017 18,722\\n29 Manipur 31,790 27,870 0.15% 4.233 20,673 19,300\\n30 Nagaland - 27,283 0.14% 4.144 - 17,647\\n31 Arunachal Pradesh - 24,603 0.13% 3.737 - 16,676\\n32 Mizoram 26,503 22,287 0.12% 3.385 18,797 16,478\\n33 Andaman & Nicobar Islands - - - - - -'"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "f50e173f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in d:\n",
    "    columns = re.split(r'\\s+', item)\n",
    "    \n",
    "    # Process the columns to extract required details\n",
    "    if len(item) >= 8:  # Check if there are enough columns\n",
    "        rank = item[1]\n",
    "        state = item[2]\n",
    "        gdp_18_19 = item[3]\n",
    "        gdp_19_20 = item[4]\n",
    "        share_18_19 = item[5]\n",
    "        gdp_billion = item[6]\n",
    "        \n",
    "        GDP_table.append([rank, state, gdp_18_19, gdp_19_20, share_18_19, gdp_billion])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "c7ed177e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP(18-19)</th>\n",
       "      <th>GSDP(19-20)</th>\n",
       "      <th>Share(18-19)</th>\n",
       "      <th>GDP($ billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil</td>\n",
       "      <td>Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar</td>\n",
       "      <td>Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>West</td>\n",
       "      <td>Bengal</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>942,586</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra</td>\n",
       "      <td>Pradesh</td>\n",
       "      <td>972,782</td>\n",
       "      <td>862,957</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td></td>\n",
       "      <td>Telangana</td>\n",
       "      <td>969,604</td>\n",
       "      <td>861,031</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya</td>\n",
       "      <td>Pradesh</td>\n",
       "      <td>906,672</td>\n",
       "      <td>809,592</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td></td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>781,653</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td></td>\n",
       "      <td>Delhi</td>\n",
       "      <td>856,112</td>\n",
       "      <td>774,870</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td></td>\n",
       "      <td>Haryana</td>\n",
       "      <td>831,610</td>\n",
       "      <td>734,163</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td></td>\n",
       "      <td>Bihar</td>\n",
       "      <td>611,804</td>\n",
       "      <td>530,363</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td></td>\n",
       "      <td>Punjab</td>\n",
       "      <td>574,760</td>\n",
       "      <td>526,376</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td></td>\n",
       "      <td>Odisha</td>\n",
       "      <td>521,275</td>\n",
       "      <td>487,805</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td></td>\n",
       "      <td>Assam</td>\n",
       "      <td>-</td>\n",
       "      <td>315,881</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td></td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>329,180</td>\n",
       "      <td>304,063</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td></td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>328,598</td>\n",
       "      <td>297,204</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td></td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>-</td>\n",
       "      <td>245,895</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp;</td>\n",
       "      <td>Kashmir</td>\n",
       "      <td>-</td>\n",
       "      <td>155,956</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal</td>\n",
       "      <td>Pradesh</td>\n",
       "      <td>165,472</td>\n",
       "      <td>153,845</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td></td>\n",
       "      <td>Goa</td>\n",
       "      <td>80,449</td>\n",
       "      <td>73,170</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td></td>\n",
       "      <td>Tripura</td>\n",
       "      <td>55,984</td>\n",
       "      <td>49,845</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td></td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>42,114</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td></td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>38,253</td>\n",
       "      <td>34,433</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td></td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>36,572</td>\n",
       "      <td>33,481</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td></td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>32,496</td>\n",
       "      <td>28,723</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td></td>\n",
       "      <td>Manipur</td>\n",
       "      <td>31,790</td>\n",
       "      <td>27,870</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td></td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>27,283</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal</td>\n",
       "      <td>Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>24,603</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td></td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>26,503</td>\n",
       "      <td>22,287</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar</td>\n",
       "      <td>Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank              State   GSDP(18-19) GSDP(19-20) Share(18-19)  \\\n",
       "1     1                      Maharashtra           -    2,632,792   \n",
       "2     2              Tamil          Nadu   1,845,853    1,630,208   \n",
       "3     3              Uttar       Pradesh   1,687,818    1,584,764   \n",
       "4     4                          Gujarat           -    1,502,899   \n",
       "5     5                        Karnataka   1,631,977    1,493,127   \n",
       "6     6               West        Bengal   1,253,832    1,089,898   \n",
       "7     7                        Rajasthan   1,020,989      942,586   \n",
       "8     8             Andhra       Pradesh     972,782      862,957   \n",
       "9     9                        Telangana     969,604      861,031   \n",
       "10   10             Madhya       Pradesh     906,672      809,592   \n",
       "11   11                           Kerala           -      781,653   \n",
       "12   12                            Delhi     856,112      774,870   \n",
       "13   13                          Haryana     831,610      734,163   \n",
       "14   14                            Bihar     611,804      530,363   \n",
       "15   15                           Punjab     574,760      526,376   \n",
       "16   16                           Odisha     521,275      487,805   \n",
       "17   17                            Assam           -      315,881   \n",
       "18   18                     Chhattisgarh     329,180      304,063   \n",
       "19   19                        Jharkhand     328,598      297,204   \n",
       "20   20                      Uttarakhand           -      245,895   \n",
       "21   21            Jammu &       Kashmir           -      155,956   \n",
       "22   22           Himachal       Pradesh     165,472      153,845   \n",
       "23   23                              Goa      80,449       73,170   \n",
       "24   24                          Tripura      55,984       49,845   \n",
       "25   25                       Chandigarh           -       42,114   \n",
       "26   26                       Puducherry      38,253       34,433   \n",
       "27   27                        Meghalaya      36,572       33,481   \n",
       "28   28                           Sikkim      32,496       28,723   \n",
       "29   29                          Manipur      31,790       27,870   \n",
       "30   30                         Nagaland           -       27,283   \n",
       "31   31          Arunachal       Pradesh           -       24,603   \n",
       "32   32                          Mizoram      26,503       22,287   \n",
       "33   33  Andaman & Nicobar       Islands           -            -   \n",
       "\n",
       "   GDP($ billion)  \n",
       "1         399.921  \n",
       "2         247.629  \n",
       "3         240.726  \n",
       "4         228.290  \n",
       "5         226.806  \n",
       "6         165.556  \n",
       "7         143.179  \n",
       "8         131.083  \n",
       "9         130.791  \n",
       "10        122.977  \n",
       "11        118.733  \n",
       "12        117.703  \n",
       "13        111.519  \n",
       "14         80.562  \n",
       "15         79.957  \n",
       "16         74.098  \n",
       "17         47.982  \n",
       "18         46.187  \n",
       "19         45.145  \n",
       "20         37.351  \n",
       "21         23.690  \n",
       "22         23.369  \n",
       "23         11.115  \n",
       "24          7.571  \n",
       "25          6.397  \n",
       "26          5.230  \n",
       "27          5.086  \n",
       "28          4.363  \n",
       "29          4.233  \n",
       "30          4.144  \n",
       "31          3.737  \n",
       "32          3.385  \n",
       "33              -  "
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['Rank', 'State', 'GSDP(18-19)', 'GSDP(19-20)', 'Share(18-19)', 'GDP($ billion)']\n",
    "df = pd.DataFrame(GDP_table, columns=columns)[1:]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a77b1bc",
   "metadata": {},
   "source": [
    "Q4. Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "79ad1fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium                                  #library that is used to work with selenium\n",
    "from selenium import webdriver                   #importing webdriver module from selenium to open automated chrome window\n",
    "import pandas as pd                              #to create DataFrame\n",
    "from selenium.webdriver.common.by import By      #importing inbuilt class By \n",
    "import warnings                                  #to ignore any sort of warning\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time                                      #use to stop search engine for few seconds\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "65e26005",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Going to the github.com using the automated chrome browser\n",
    "driver =webdriver.Chrome()\n",
    "driver.get(\"https://github.com/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d9420c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click on the 'open source' \n",
    "button = driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button')\n",
    "button.click()\n",
    "\n",
    "trending = driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/div[3]/ul/li[2]/a')\n",
    "trending.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "798a6be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles =[]\n",
    "title = driver.find_elements(By.XPATH,'//h2[@class=\"h3 lh-condensed\"]')\n",
    "for i in title:\n",
    "    t= i.text\n",
    "    titles.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "46a2bb73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "85812759",
   "metadata": {},
   "outputs": [],
   "source": [
    "description = []\n",
    "des = driver.find_elements(By.XPATH, '/html/body/div[1]/div[4]/main/div[3]/div/div[2]/article/p')\n",
    "for i in des:\n",
    "    try:\n",
    "        description.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1250ef10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a2d093ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "contributor = []\n",
    "count = driver.find_elements(By.XPATH, '/html/body/div[1]/div[4]/main/div[3]/div/div[2]/article/div[2]/a')\n",
    "for i in count:\n",
    "    c=i.text\n",
    "    contributor.append(c)\n",
    "conts = []\n",
    "for i in range(1, len(contributors),2):\n",
    "    number = re.sub(r'[^\\d]','',contributors[i])\n",
    "    conts.append(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "29ac0f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(conts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7ec486c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = []\n",
    "lan = driver.find_elements(By.XPATH,'//span[@class=\"d-inline-block ml-0 mr-3\"]')\n",
    "for i in lan:\n",
    "    try:\n",
    "        l=i.text\n",
    "        languages.append(l)\n",
    "    except NoSuchElementException:\n",
    "        languages.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d69904e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2b2d1719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Contributors</th>\n",
       "      <th>Languages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>getumbrel / llama-gpt</td>\n",
       "      <td>A self-hosted, offline, ChatGPT-like chatbot. ...</td>\n",
       "      <td>166</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ill-inc / biomes-game</td>\n",
       "      <td>Biomes is an open source sandbox MMORPG built ...</td>\n",
       "      <td>130</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>roboflow / supervision</td>\n",
       "      <td>We write your reusable computer vision tools. 💜</td>\n",
       "      <td>202</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>elidianaandrade / dio-lab-open-source</td>\n",
       "      <td>Repositório do lab Contribuindo em um Projeto ...</td>\n",
       "      <td>3432</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a16z-infra / ai-town</td>\n",
       "      <td>A MIT-licensed, deployable starter kit for bui...</td>\n",
       "      <td>275</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>qiuyu96 / CoDeF</td>\n",
       "      <td>Official PyTorch implementation of CoDeF: Cont...</td>\n",
       "      <td>37</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>StanGirard / quivr</td>\n",
       "      <td>Your Second Brain powered by Generative AI 🧠 D...</td>\n",
       "      <td>2164</td>\n",
       "      <td>PHP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>byoungd / English-level-up-tips</td>\n",
       "      <td>An advanced guide to learn English which might...</td>\n",
       "      <td>3401</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>digininja / DVWA</td>\n",
       "      <td>Damn Vulnerable Web Application (DVWA)</td>\n",
       "      <td>2819</td>\n",
       "      <td>HTML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>kubernetes-sigs / external-dns</td>\n",
       "      <td>Configure external DNS servers (AWS Route53, G...</td>\n",
       "      <td>2395</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>opentffoundation / manifesto</td>\n",
       "      <td>The OpenTF Manifesto expresses concern over Ha...</td>\n",
       "      <td>466</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ascoders / weekly</td>\n",
       "      <td>前端精读周刊。帮你理解最前沿、实用的技术。</td>\n",
       "      <td>2921</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>danswer-ai / danswer</td>\n",
       "      <td>Ask Questions in natural language and get Answ...</td>\n",
       "      <td>294</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>chatchat-space / Langchain-Chatchat</td>\n",
       "      <td>Langchain-Chatchat (formerly langchain-ChatGLM...</td>\n",
       "      <td>2326</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1Panel-dev / 1Panel</td>\n",
       "      <td>🔥 🔥 🔥 现代化、开源的 Linux 服务器运维管理面板。</td>\n",
       "      <td>848</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>google / googletest</td>\n",
       "      <td>GoogleTest - Google Testing and Mocking Framework</td>\n",
       "      <td>9753</td>\n",
       "      <td>Shell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>openai / whisper</td>\n",
       "      <td>Robust Speech Recognition via Large-Scale Weak...</td>\n",
       "      <td>4943</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>QiuChenlyOpenSource / InjectLib</td>\n",
       "      <td>基于Ruby编写的命令行注入版本</td>\n",
       "      <td>457</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>kuafuai / DevOpsGPT</td>\n",
       "      <td>Multi agent system for AI-driven software deve...</td>\n",
       "      <td>244</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>yujiangshui / A-Programmers-Guide-to-English</td>\n",
       "      <td>专为程序员编写的英语学习指南 v1.2。在线版本请点 -&gt;</td>\n",
       "      <td>1337</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>steven-tey / novel</td>\n",
       "      <td>Notion-style WYSIWYG editor with AI-powered au...</td>\n",
       "      <td>602</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>facebookresearch / AnimatedDrawings</td>\n",
       "      <td>Code to accompany \"A Method for Animating Chil...</td>\n",
       "      <td>713</td>\n",
       "      <td>CSS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Title  \\\n",
       "0                          getumbrel / llama-gpt   \n",
       "1                          ill-inc / biomes-game   \n",
       "2                         roboflow / supervision   \n",
       "3          elidianaandrade / dio-lab-open-source   \n",
       "4                           a16z-infra / ai-town   \n",
       "5                                qiuyu96 / CoDeF   \n",
       "6                             StanGirard / quivr   \n",
       "7                byoungd / English-level-up-tips   \n",
       "8                               digininja / DVWA   \n",
       "9                 kubernetes-sigs / external-dns   \n",
       "10                  opentffoundation / manifesto   \n",
       "11                             ascoders / weekly   \n",
       "12                          danswer-ai / danswer   \n",
       "13           chatchat-space / Langchain-Chatchat   \n",
       "14                           1Panel-dev / 1Panel   \n",
       "15                           google / googletest   \n",
       "16                              openai / whisper   \n",
       "17               QiuChenlyOpenSource / InjectLib   \n",
       "18                           kuafuai / DevOpsGPT   \n",
       "19  yujiangshui / A-Programmers-Guide-to-English   \n",
       "20                            steven-tey / novel   \n",
       "21           facebookresearch / AnimatedDrawings   \n",
       "\n",
       "                                          Description Contributors   Languages  \n",
       "0   A self-hosted, offline, ChatGPT-like chatbot. ...          166  TypeScript  \n",
       "1   Biomes is an open source sandbox MMORPG built ...          130  TypeScript  \n",
       "2     We write your reusable computer vision tools. 💜          202      Python  \n",
       "3   Repositório do lab Contribuindo em um Projeto ...         3432  TypeScript  \n",
       "4   A MIT-licensed, deployable starter kit for bui...          275      Python  \n",
       "5   Official PyTorch implementation of CoDeF: Cont...           37  TypeScript  \n",
       "6   Your Second Brain powered by Generative AI 🧠 D...         2164         PHP  \n",
       "7   An advanced guide to learn English which might...         3401          Go  \n",
       "8              Damn Vulnerable Web Application (DVWA)         2819        HTML  \n",
       "9   Configure external DNS servers (AWS Route53, G...         2395  JavaScript  \n",
       "10  The OpenTF Manifesto expresses concern over Ha...          466      Python  \n",
       "11                              前端精读周刊。帮你理解最前沿、实用的技术。         2921      Python  \n",
       "12  Ask Questions in natural language and get Answ...          294          Go  \n",
       "13  Langchain-Chatchat (formerly langchain-ChatGLM...         2326         C++  \n",
       "14                     🔥 🔥 🔥 现代化、开源的 Linux 服务器运维管理面板。          848      Python  \n",
       "15  GoogleTest - Google Testing and Mocking Framework         9753       Shell  \n",
       "16  Robust Speech Recognition via Large-Scale Weak...         4943      Python  \n",
       "17                                   基于Ruby编写的命令行注入版本          457  TypeScript  \n",
       "18  Multi agent system for AI-driven software deve...          244      Python  \n",
       "19                      专为程序员编写的英语学习指南 v1.2。在线版本请点 ->         1337      Python  \n",
       "20  Notion-style WYSIWYG editor with AI-powered au...          602      Python  \n",
       "21  Code to accompany \"A Method for Animating Chil...          713         CSS  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.DataFrame({'Title': titles[0:22],'Description': description[0:22],'Contributors': conts[0:22],'Languages': languages[0:22]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dc285147",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfe09a5",
   "metadata": {},
   "source": [
    "Q5. Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "18e7e15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium                                  #library that is used to work with selenium\n",
    "from selenium import webdriver                   #importing webdriver module from selenium to open automated chrome window\n",
    "import pandas as pd                              #to create DataFrame\n",
    "from selenium.webdriver.common.by import By      #importing inbuilt class By \n",
    "import warnings                                  #to ignore any sort of warning\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time                                      #use to stop search engine for few seconds\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f84b41f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https:/www.billboard.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2254d62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "charts = driver.find_element(By.XPATH,'/html/body/div[3]/header/div/div[2]/div/div/div[2]/div[2]/div/div/nav/ul/li[1]/a')\n",
    "charts.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e380e7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Click on View chart button\n",
    "view_chart_button = driver.find_element(By.XPATH,'/html/body/div[3]/main/div[2]/div[1]/div[1]/div/div/div[3]/a')\n",
    "view_chart_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039c4c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "song =[class=\"c-title  a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 lrv-u-font-size-18@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-330 u-max-width-230@tablet-only\"]\n",
    "artist =[class=\"c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only\"]\n",
    "last_week and weeksonchart =[class=\"o-chart-results-list__item // a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-background-color-white-064@mobile-max u-hidden@mobile-max\"]\n",
    "peak = /html/body/div[3]/main/div[2]/div[3]/div/div/div/div[2]/div[2]/ul/li[4]/ul/li[5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "391093b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = []\n",
    "rank = driver.find_elements(By.XPATH, '//li[@class=\"o-chart-results-list__item // lrv-u-background-color-black lrv-u-color-white u-width-100 u-width-55@mobile-max u-width-55@tablet-only lrv-u-height-100p lrv-u-flex lrv-u-flex-direction-column@mobile-max lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey\"]')\n",
    "for i in rank:\n",
    "    r=i.text\n",
    "    ranks.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "58493f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ranks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a44de72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = []\n",
    "song = driver.find_elements(By.XPATH,'/html/body/div[3]/main/div[2]/div[3]/div/div/div/div[2]/div/ul/li/ul/li/h3')\n",
    "for i in song:\n",
    "    s=i.text\n",
    "    songs.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "bdfc355e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "6ac6448f",
   "metadata": {},
   "outputs": [],
   "source": [
    "artists =[]\n",
    "artist = driver.find_elements(By.XPATH,'/html/body/div/main/div/div/div/div/div/div/div/ul/li/ul/li[1]/span')\n",
    "for i in artist:\n",
    "    a=i.text\n",
    "    artists.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ebe06e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f483d958",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_week = []\n",
    "lists = driver.find_elements(By.XPATH,'//li[@class=\"o-chart-results-list__item // a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-background-color-white-064@mobile-max u-hidden@mobile-max\"]')\n",
    "for i in lists:\n",
    "    lw = i.text\n",
    "    last_week.append(lw)\n",
    "    \n",
    "lastweek=[]\n",
    "for i in range(0, len(last_week),2):\n",
    "    number = re.sub(r'[^\\d]','',last_week[i])\n",
    "    lastweek.append(number)\n",
    "weeks_on_chart=[]\n",
    "for i in range(1, len(last_week),2):\n",
    "    number = re.sub(r'[^\\d]','',last_week[i])\n",
    "    weeks_on_chart.append(number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "64359026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lastweek),len(weeks_on_chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2d0b4b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks =[]\n",
    "peak =driver.find_elements(By.XPATH,'//li[@class=\"o-chart-results-list__item // a-chart-bg-color a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-background-color-grey-lightest lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-hidden@mobile-max\"]')\n",
    "for i in peak:\n",
    "    p=i.text\n",
    "    peaks.append(p)\n",
    "peak_rank=[]\n",
    "for i in range(1, len(peaks), 2):\n",
    "    number = re.sub(r'[^\\d]','',peaks[i])\n",
    "    peak_rank.append(number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d0cae980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(peak_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f509f711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Last Week Rank</th>\n",
       "      <th>Peak Rank</th>\n",
       "      <th>Weeks on Chart</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Last Night</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Fast Car</td>\n",
       "      <td>Luke Combs</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Cruel Summer</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Calm Down</td>\n",
       "      <td>Rema &amp; Selena Gomez</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fukumean</td>\n",
       "      <td>Gunna</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>Lagunas</td>\n",
       "      <td>Peso Pluma &amp; Jasiel Nunez</td>\n",
       "      <td></td>\n",
       "      <td>77</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>Overdrive</td>\n",
       "      <td>Post Malone</td>\n",
       "      <td>68</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>Bzrp Music Sessions, Vol. 55</td>\n",
       "      <td>Bizarrap &amp; Peso Pluma</td>\n",
       "      <td>99</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>Dawns</td>\n",
       "      <td>Zach Bryan Featuring Maggie Rogers</td>\n",
       "      <td></td>\n",
       "      <td>42</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>Rubicon</td>\n",
       "      <td>Peso Pluma</td>\n",
       "      <td></td>\n",
       "      <td>63</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                     Song Name                              Artist  \\\n",
       "0     1                    Last Night                       Morgan Wallen   \n",
       "1     2                      Fast Car                          Luke Combs   \n",
       "2     3                  Cruel Summer                        Taylor Swift   \n",
       "3     4                     Calm Down                 Rema & Selena Gomez   \n",
       "4     5                      Fukumean                               Gunna   \n",
       "..  ...                           ...                                 ...   \n",
       "95   96                       Lagunas           Peso Pluma & Jasiel Nunez   \n",
       "96   97                     Overdrive                         Post Malone   \n",
       "97   98  Bzrp Music Sessions, Vol. 55               Bizarrap & Peso Pluma   \n",
       "98   99                         Dawns  Zach Bryan Featuring Maggie Rogers   \n",
       "99  100                       Rubicon                          Peso Pluma   \n",
       "\n",
       "   Last Week Rank Peak Rank Weeks on Chart  \n",
       "0               1         1             28  \n",
       "1               2         2             20  \n",
       "2               4         3             14  \n",
       "3               6         3             49  \n",
       "4               7         4              8  \n",
       "..            ...       ...            ...  \n",
       "95                       77              6  \n",
       "96             68        47              3  \n",
       "97             99        31             10  \n",
       "98                       42             15  \n",
       "99                       63              6  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.DataFrame({'Rank':ranks,'Song Name':songs, 'Artist':artists, 'Last Week Rank':lastweek, 'Peak Rank':peak_rank, 'Weeks on Chart':weeks_on_chart})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "89484510",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3044ee4c",
   "metadata": {},
   "source": [
    "Q6.Scrape the details of Highest selling novels.\n",
    "compare\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "daa754e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium                                  #library that is used to work with selenium\n",
    "from selenium import webdriver                   #importing webdriver module from selenium to open automated chrome window\n",
    "import pandas as pd                              #to create DataFrame\n",
    "from selenium.webdriver.common.by import By      #importing inbuilt class By \n",
    "import warnings                                  #to ignore any sort of warning\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time                                      #use to stop search engine for few seconds\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "d5adc7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "54784e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty list\n",
    "Book_name = []\n",
    "Author_name = []\n",
    "Volumes_sold = []\n",
    "Publisher = []\n",
    "Genre = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "72512189",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping book names data\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody//tr/td[2]\"):\n",
    "    Book_name.append(i.text)\n",
    "\n",
    "    \n",
    "#Scraping author names data\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody/tr/td[3]\"):\n",
    "    try:\n",
    "        if i.text == '0' : raise NoSuchElementException\n",
    "        Author_name.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Author_name.append('-')\n",
    "time.sleep(1)\n",
    "\n",
    "\n",
    "#Scraping data of volumes sold\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody/tr/td[4]\"):\n",
    "    Volumes_sold.append(i.text)\n",
    "\n",
    "    \n",
    "#Scraping data of publisher names\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody/tr/td[5]\"):\n",
    "    Publisher.append(i.text)\n",
    "\n",
    "    \n",
    "#Scraping data of genre\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody/tr/td[6]\"):\n",
    "    Genre.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "94762075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author</th>\n",
       "      <th>Volume sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name            Author  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volume sold        Publisher                        Genre  \n",
       "0    5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1    4,475,152       Bloomsbury           Children's Fiction  \n",
       "2    4,200,654       Bloomsbury           Children's Fiction  \n",
       "3    4,179,479       Bloomsbury           Children's Fiction  \n",
       "4    3,758,936     Random House              Romance & Sagas  \n",
       "..         ...              ...                          ...  \n",
       "95     807,311     Random House   General & Literary Fiction  \n",
       "96     794,201          Penguin        Food & Drink: General  \n",
       "97     792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98     791,507            Orion           Biography: General  \n",
       "99     791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe for scraped data\n",
    "Novels = pd.DataFrame({})\n",
    "Novels['Book Name'] = Book_name\n",
    "Novels['Author'] = Author_name\n",
    "Novels['Volume sold'] = Volumes_sold\n",
    "Novels['Publisher'] = Publisher\n",
    "Novels['Genre'] = Genre\n",
    "Novels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "c7d9119c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57067a21",
   "metadata": {},
   "source": [
    "Q7. Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/ You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "afe0ce38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium                                  #library that is used to work with selenium\n",
    "from selenium import webdriver                   #importing webdriver module from selenium to open automated chrome window\n",
    "import pandas as pd                              #to create DataFrame\n",
    "from selenium.webdriver.common.by import By      #importing inbuilt class By \n",
    "import warnings                                  #to ignore any sort of warning\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time                                      #use to stop search engine for few seconds\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "57ae0f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.imdb.com/list/ls095964455/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "f1fc35a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "name = driver.find_elements(By.CLASS_NAME, \"lister-item-header\")\n",
    "for i in name:\n",
    "    n=i.text\n",
    "    names.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "f520b0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = []\n",
    "year = driver.find_elements(By.XPATH, '//span[@class=\"lister-item-year text-muted unbold\"]')\n",
    "for i in year:\n",
    "    y=i.text\n",
    "    years.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "688347a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "51160f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre = []\n",
    "genre_ =  driver.find_elements(By.CLASS_NAME, \"genre\")\n",
    "for i in genre_:\n",
    "    g=i.text\n",
    "    genre.append(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "7b39cd07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "5b6c95be",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime = []\n",
    "runtime_ = driver.find_elements(By.CLASS_NAME, \"runtime\")\n",
    "for i in runtime_:\n",
    "    r=i.text\n",
    "    runtime.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "026e3b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "c4975aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = []\n",
    "rating = driver.find_elements(By.CLASS_NAME,\"ipl-rating-widget\")\n",
    "for i in rating:\n",
    "    r=i.text.split('\\n')[0] \n",
    "    ratings.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a45e9ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "votes = []\n",
    "vote = driver.find_elements(By.NAME, \"nv\")\n",
    "for i in vote:\n",
    "    v=i.text\n",
    "    votes.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "db504803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titles</th>\n",
       "      <th>Year span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. Game of Thrones (2011–2019)</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,193,010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2. Stranger Things (2016–2024)</td>\n",
       "      <td>(2016–2024)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,266,779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3. The Walking Dead (2010–2022)</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,040,933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4. 13 Reasons Why (2017–2020)</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>305,951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5. The 100 (2014–2020)</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>265,023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96. Reign (2013–2017)</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>52,423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97. A Series of Unfortunate Events (2017–2019)</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>64,451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98. Criminal Minds (2005– )</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>210,093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99. Scream: The TV Series (2015–2019)</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7</td>\n",
       "      <td>43,681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100. The Haunting of Hill House (2018)</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>263,647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Titles    Year span  \\\n",
       "0                   1. Game of Thrones (2011–2019)  (2011–2019)   \n",
       "1                   2. Stranger Things (2016–2024)  (2016–2024)   \n",
       "2                  3. The Walking Dead (2010–2022)  (2010–2022)   \n",
       "3                    4. 13 Reasons Why (2017–2020)  (2017–2020)   \n",
       "4                           5. The 100 (2014–2020)  (2014–2020)   \n",
       "..                                             ...          ...   \n",
       "95                           96. Reign (2013–2017)  (2013–2017)   \n",
       "96  97. A Series of Unfortunate Events (2017–2019)  (2017–2019)   \n",
       "97                     98. Criminal Minds (2005– )     (2005– )   \n",
       "98           99. Scream: The TV Series (2015–2019)  (2015–2019)   \n",
       "99          100. The Haunting of Hill House (2018)       (2018)   \n",
       "\n",
       "                       Genre Run time Ratings      Votes  \n",
       "0   Action, Adventure, Drama   57 min     9.2  2,193,010  \n",
       "1     Drama, Fantasy, Horror   51 min     8.7  1,266,779  \n",
       "2    Drama, Horror, Thriller   44 min     8.1  1,040,933  \n",
       "3   Drama, Mystery, Thriller   60 min     7.5    305,951  \n",
       "4     Drama, Mystery, Sci-Fi   43 min     7.6    265,023  \n",
       "..                       ...      ...     ...        ...  \n",
       "95                     Drama   42 min     7.4     52,423  \n",
       "96  Adventure, Comedy, Drama   50 min     7.8     64,451  \n",
       "97     Crime, Drama, Mystery   42 min     8.1    210,093  \n",
       "98      Comedy, Crime, Drama   45 min       7     43,681  \n",
       "99    Drama, Horror, Mystery  572 min     8.6    263,647  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.DataFrame({'Titles':names, 'Year span': years, 'Genre':genre, 'Run time':runtime, 'Ratings':ratings, 'Votes':votes})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "96795b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f1ab88",
   "metadata": {},
   "source": [
    "Q8. Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute G) Year\n",
    "Note: - from the home page you have to go to the Show All Dataset page through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "ab85a5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium                                  #library that is used to work with selenium\n",
    "from selenium import webdriver                   #importing webdriver module from selenium to open automated chrome window\n",
    "import pandas as pd                              #to create DataFrame\n",
    "from selenium.webdriver.common.by import By      #importing inbuilt class By \n",
    "import warnings                                  #to ignore any sort of warning\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time                                      #use to stop search engine for few seconds\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException,ElementNotInteractableException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "dffbdd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error getting version of chromedriver 115. Retrying with chromedriver 114 (attempt 1/5)\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://archive.ics.uci.edu/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "decbea5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = driver.find_element(By.XPATH,'//a[@href=\"/datasets\"]')\n",
    "datasets.click()\n",
    "\n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "f4da0abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "wait = WebDriverWait(driver, 10)\n",
    "rowsperpage = wait.until(EC.presence_of_element_located((By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[2]/div[3]/label/select')))\n",
    "rowsperpage.click()\n",
    "\n",
    "dropdown = driver.find_element(By.XPATH,\"/html/body/div/div[1]/div[1]/main/div/div[2]/div[3]/label/select/option[5]\")\n",
    "dropdown.click()\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6f2546",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "6f7f4767",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []\n",
    "data_type= []\n",
    "task = []\n",
    "attribute_type= []\n",
    "no_of_instances=[]\n",
    "no_of_attributes= []\n",
    "year =[]\n",
    "\n",
    "title = driver.find_elements(By.XPATH,'//a[@class=\"link-hover link text-xl font-semibold\"]')\n",
    "for i in title:\n",
    "    t=i.text\n",
    "    titles.append(t)           \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "c61bcd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data = driver.find_elements(By.XPATH,'//p[@class=\"truncate\"]')\n",
    "    for i in data:\n",
    "        d=i.text\n",
    "        data_type.append(d)\n",
    "except NoSuchElementException:\n",
    "    data_type.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "d1b6dcd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "db70cf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = []\n",
    "try:\n",
    "    tasks = driver.find_elements(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[2]/div/div/div/div[2]/div/div[1]/span')\n",
    "    for i in tasks:\n",
    "        task.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    task.append(\"-\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "bf1340c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "cd6b45ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    attribute = driver.find_elements(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[2]/div/div/div/div[2]/div/div[2]/span')\n",
    "    for i in attribute:\n",
    "        attribute_type.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    attribute_type.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "fdc6c939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(attribute_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "0b8dcb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    instance =driver.find_elements(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div/div[2]/div/div/div[2]/div/div[3]/span')\n",
    "    for i in instance:\n",
    "        no_of_instances.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    no_of_instances.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "9d8120d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(no_of_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "32ae4225",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    attributes = driver.find_elements(By.XPATH,\"/html/body/div/div[1]/div[1]/main/div/div/div[2]/div/div/div[2]/div/div[4]/span\")\n",
    "    for i in attributes:\n",
    "        no_of_attributes.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    no_of_attributes.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "1a80ff73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(no_of_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "91f275fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    years= driver.find_elements(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[3]')\n",
    "    for i in years:\n",
    "        year.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    year.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "b839ae5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "5b8e3dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titles</th>\n",
       "      <th>Data_Type</th>\n",
       "      <th>Tasks</th>\n",
       "      <th>Attribute_Type</th>\n",
       "      <th>No_of_instances</th>\n",
       "      <th>No_of_attributes</th>\n",
       "      <th>Years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>A small classic dataset from Fisher, 1936. One...</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>150 Instances</td>\n",
       "      <td>4 Attributes</td>\n",
       "      <td>7/1/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>4 databases: Cleveland, Hungary, Switzerland, ...</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>303 Instances</td>\n",
       "      <td>13 Attributes</td>\n",
       "      <td>7/1/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Predict whether income exceeds $50K/yr based o...</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>48.84K Instances</td>\n",
       "      <td>14 Attributes</td>\n",
       "      <td>5/1/1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dry Bean Dataset</td>\n",
       "      <td>Images of 13,611 grains of 7 different registe...</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>13.61K Instances</td>\n",
       "      <td>16 Attributes</td>\n",
       "      <td>9/14/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>This diabetes dataset is from AIM '94</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>20 Attributes</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Using chemical analysis determine the origin o...</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>178 Instances</td>\n",
       "      <td>13 Attributes</td>\n",
       "      <td>7/1/1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td>Diagnostic Wisconsin Breast Cancer Database.</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>569 Instances</td>\n",
       "      <td>30 Attributes</td>\n",
       "      <td>11/1/1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Car Evaluation</td>\n",
       "      <td>Derived from simple hierarchical decision mode...</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>1.73K Instances</td>\n",
       "      <td>6 Attributes</td>\n",
       "      <td>6/1/1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rice (Cammeo and Osmancik)</td>\n",
       "      <td>A total of 3810 rice grain's images were taken...</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>3.81K Instances</td>\n",
       "      <td>8 Attributes</td>\n",
       "      <td>10/6/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mushroom</td>\n",
       "      <td>From Audobon Society Field Guide; mushrooms de...</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>8.12K Instances</td>\n",
       "      <td>22 Attributes</td>\n",
       "      <td>4/27/1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Predict the age of abalone from physical measu...</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>4.18K Instances</td>\n",
       "      <td>8 Attributes</td>\n",
       "      <td>12/1/1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Breast Cancer</td>\n",
       "      <td>Breast Cancer Data (Restricted Access)</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>286 Instances</td>\n",
       "      <td>9 Attributes</td>\n",
       "      <td>7/11/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Statlog (German Credit Data)</td>\n",
       "      <td>This dataset classifies people described by a ...</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>1K Instances</td>\n",
       "      <td>20 Attributes</td>\n",
       "      <td>11/17/1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Wine Quality</td>\n",
       "      <td>Two datasets are included, related to red and ...</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>4.9K Instances</td>\n",
       "      <td>12 Attributes</td>\n",
       "      <td>10/7/2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Glass Identification</td>\n",
       "      <td>From USA Forensic Science Service; 6 types of ...</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>214 Instances</td>\n",
       "      <td>9 Attributes</td>\n",
       "      <td>9/1/1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Census Income</td>\n",
       "      <td>Predict whether income exceeds $50K/yr based o...</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>48.84K Instances</td>\n",
       "      <td>14 Attributes</td>\n",
       "      <td>5/1/1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Breast Cancer Wisconsin (Original)</td>\n",
       "      <td>Original Wisconsin Breast Cancer Database</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>699 Instances</td>\n",
       "      <td>9 Attributes</td>\n",
       "      <td>7/15/1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Automobile</td>\n",
       "      <td>From 1985 Ward's Automotive Yearbook</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>205 Instances</td>\n",
       "      <td>25 Attributes</td>\n",
       "      <td>5/19/1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Auto MPG</td>\n",
       "      <td>Revised from CMU StatLib library, data concern...</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>398 Instances</td>\n",
       "      <td>7 Attributes</td>\n",
       "      <td>7/7/1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Bank Marketing</td>\n",
       "      <td>The data is related with direct marketing camp...</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>45.21K Instances</td>\n",
       "      <td>17 Attributes</td>\n",
       "      <td>2/14/2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Thyroid Disease</td>\n",
       "      <td>10 separate databases from Garavan Institute</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Multivariate, Domain-Theory</td>\n",
       "      <td>7.2K Instances</td>\n",
       "      <td>5 Attributes</td>\n",
       "      <td>1/1/1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Spambase</td>\n",
       "      <td>Classifying Email as Spam or Non-Spam</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>4.6K Instances</td>\n",
       "      <td>57 Attributes</td>\n",
       "      <td>7/1/1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Predict students' dropout and academic success</td>\n",
       "      <td>A dataset created from a higher education inst...</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>4.42K Instances</td>\n",
       "      <td>36 Attributes</td>\n",
       "      <td>12/13/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Optical Recognition of Handwritten Digits</td>\n",
       "      <td>Two versions of this database available; see f...</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>5.62K Instances</td>\n",
       "      <td>64 Attributes</td>\n",
       "      <td>7/1/1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Credit Approval</td>\n",
       "      <td>This data concerns credit card applications; g...</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>690 Instances</td>\n",
       "      <td>15 Attributes</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Titles  \\\n",
       "0                                             Iris   \n",
       "1                                    Heart Disease   \n",
       "2                                            Adult   \n",
       "3                                 Dry Bean Dataset   \n",
       "4                                         Diabetes   \n",
       "5                                             Wine   \n",
       "6             Breast Cancer Wisconsin (Diagnostic)   \n",
       "7                                   Car Evaluation   \n",
       "8                       Rice (Cammeo and Osmancik)   \n",
       "9                                         Mushroom   \n",
       "10                                         Abalone   \n",
       "11                                   Breast Cancer   \n",
       "12                    Statlog (German Credit Data)   \n",
       "13                                    Wine Quality   \n",
       "14                            Glass Identification   \n",
       "15                                   Census Income   \n",
       "16              Breast Cancer Wisconsin (Original)   \n",
       "17                                      Automobile   \n",
       "18                                        Auto MPG   \n",
       "19                                  Bank Marketing   \n",
       "20                                 Thyroid Disease   \n",
       "21                                        Spambase   \n",
       "22  Predict students' dropout and academic success   \n",
       "23       Optical Recognition of Handwritten Digits   \n",
       "24                                 Credit Approval   \n",
       "\n",
       "                                            Data_Type  \\\n",
       "0   A small classic dataset from Fisher, 1936. One...   \n",
       "1   4 databases: Cleveland, Hungary, Switzerland, ...   \n",
       "2   Predict whether income exceeds $50K/yr based o...   \n",
       "3   Images of 13,611 grains of 7 different registe...   \n",
       "4               This diabetes dataset is from AIM '94   \n",
       "5   Using chemical analysis determine the origin o...   \n",
       "6        Diagnostic Wisconsin Breast Cancer Database.   \n",
       "7   Derived from simple hierarchical decision mode...   \n",
       "8   A total of 3810 rice grain's images were taken...   \n",
       "9   From Audobon Society Field Guide; mushrooms de...   \n",
       "10  Predict the age of abalone from physical measu...   \n",
       "11             Breast Cancer Data (Restricted Access)   \n",
       "12  This dataset classifies people described by a ...   \n",
       "13  Two datasets are included, related to red and ...   \n",
       "14  From USA Forensic Science Service; 6 types of ...   \n",
       "15  Predict whether income exceeds $50K/yr based o...   \n",
       "16          Original Wisconsin Breast Cancer Database   \n",
       "17               From 1985 Ward's Automotive Yearbook   \n",
       "18  Revised from CMU StatLib library, data concern...   \n",
       "19  The data is related with direct marketing camp...   \n",
       "20       10 separate databases from Garavan Institute   \n",
       "21              Classifying Email as Spam or Non-Spam   \n",
       "22  A dataset created from a higher education inst...   \n",
       "23  Two versions of this database available; see f...   \n",
       "24  This data concerns credit card applications; g...   \n",
       "\n",
       "                         Tasks               Attribute_Type   No_of_instances  \\\n",
       "0               Classification                 Multivariate     150 Instances   \n",
       "1               Classification                 Multivariate     303 Instances   \n",
       "2               Classification                 Multivariate  48.84K Instances   \n",
       "3               Classification                 Multivariate  13.61K Instances   \n",
       "4                                                                               \n",
       "5               Classification                 Multivariate     178 Instances   \n",
       "6               Classification                 Multivariate     569 Instances   \n",
       "7               Classification                 Multivariate   1.73K Instances   \n",
       "8               Classification                 Multivariate   3.81K Instances   \n",
       "9               Classification                 Multivariate   8.12K Instances   \n",
       "10              Classification                 Multivariate   4.18K Instances   \n",
       "11              Classification                 Multivariate     286 Instances   \n",
       "12              Classification                 Multivariate      1K Instances   \n",
       "13  Classification, Regression                 Multivariate    4.9K Instances   \n",
       "14              Classification                 Multivariate     214 Instances   \n",
       "15              Classification                 Multivariate  48.84K Instances   \n",
       "16              Classification                 Multivariate     699 Instances   \n",
       "17                  Regression                 Multivariate     205 Instances   \n",
       "18                  Regression                 Multivariate     398 Instances   \n",
       "19              Classification                 Multivariate  45.21K Instances   \n",
       "20              Classification  Multivariate, Domain-Theory    7.2K Instances   \n",
       "21              Classification                 Multivariate    4.6K Instances   \n",
       "22              Classification                      Tabular   4.42K Instances   \n",
       "23              Classification                 Multivariate   5.62K Instances   \n",
       "24              Classification                 Multivariate     690 Instances   \n",
       "\n",
       "   No_of_attributes       Years  \n",
       "0      4 Attributes    7/1/1988  \n",
       "1     13 Attributes    7/1/1988  \n",
       "2     14 Attributes    5/1/1996  \n",
       "3     16 Attributes   9/14/2020  \n",
       "4     20 Attributes         N/A  \n",
       "5     13 Attributes    7/1/1991  \n",
       "6     30 Attributes   11/1/1995  \n",
       "7      6 Attributes    6/1/1997  \n",
       "8      8 Attributes   10/6/2019  \n",
       "9     22 Attributes   4/27/1987  \n",
       "10     8 Attributes   12/1/1995  \n",
       "11     9 Attributes   7/11/1988  \n",
       "12    20 Attributes  11/17/1994  \n",
       "13    12 Attributes   10/7/2009  \n",
       "14     9 Attributes    9/1/1987  \n",
       "15    14 Attributes    5/1/1996  \n",
       "16     9 Attributes   7/15/1992  \n",
       "17    25 Attributes   5/19/1987  \n",
       "18     7 Attributes    7/7/1993  \n",
       "19    17 Attributes   2/14/2012  \n",
       "20     5 Attributes    1/1/1987  \n",
       "21    57 Attributes    7/1/1999  \n",
       "22    36 Attributes  12/13/2021  \n",
       "23    64 Attributes    7/1/1998  \n",
       "24    15 Attributes         N/A  "
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.DataFrame({'Titles': titles,'Data_Type':data_type,'Tasks':task,'Attribute_Type':attribute_type,'No_of_instances':no_of_instances,'No_of_attributes':no_of_attributes,'Years':year})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "56c6f96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffde02dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
